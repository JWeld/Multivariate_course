---
title: "Friday"
editor_options: 
  markdown: 
    wrap: 72
---

Sometimes loaded packages in R can conflict with another package. Among
other issues, this can mean that the same function name (e.g. select())
is used in different packages, so the your code may give a different
output (or fail) depending on the packages you have loaded at the time!
By default, R uses the most recently loaded version of the function.
This can be over-ridden using the "conflicted" package. It is good
practice to write code that has a narrow purpose and loads the packages
needed for that purpose, rather than one huge script running many
different analyses. However, you may sometimes need to unload a package
or restart R to get the expected results. You can restart R (note: not
the same as restarting RStudio!) from the RStudio Session menu or using
the following code. The code is commented out because we don't actually
need to do this now, but it is good to know!

```{r}
#VIM package loaded on Tuesday conflicts with SIMPER function in Vegan which we will use today, if you wanted to use SIMPER after VIM you can detach VIM first
#detach("package:VIM", unload=TRUE, force = TRUE)

#Alternatively you can restart R and load only the packages you need
#.rs.restartR()
```

Now load the packages we need today

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(vegan)
library(MASS)
library(tidyverse)
library(labdsv)
library(caret)
library(gllvm) #Generalised linear latent variable models
library(readxl)
library(mvabund)
library(lattice)
library(pls)

library(devtools)
install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")
library(pairwiseAdonis)
```

Load the data we are using

```{r}
data("dune")
data("dune.env")
dummy_management <-
  as.data.frame(model.matrix(~ Management - 1, data = dune.env))
#add these to the dataset
dune.env.original <-
  dune.env #we keep a copy of the original version
dune.env <-
  dune.env %>% select(A1, Moisture, Manure, Use) %>% cbind(., dummy_management)
dune.env$Moisture <-
  as.numeric(as.character(dune.env$Moisture)) #make numeric
dune.env$Manure <- as.numeric(as.character(dune.env$Manure))
dune.env$Use <- as.numeric(dune.env$Use)
#make column names shorter
dune.env <-
  dune.env %>% rename(BF = ManagementBF,
                      HF = ManagementHF,
                      NM = ManagementNM,
                      SF = ManagementSF)
```

### [Exercise 30: Differences between groups. ANOSIM, adonis and SIMPER]{style="color:cornflowerblue"}

ANOSIM (Analysis Of Similarities) is a non-parametric test of
significant difference between two or more groups, based on any distance
measure. In this case, use the clusters from the K-means exercise.
Change to Bray-Curtis similarity index.

ANOSIM gives you the P value and an R value. R value close to 1
indicates high separation between levels of your factor while R value
close to 0 indicate no separation between levels of your factor.

Try also the recommended alternative "adonis" - Analysis of variance
using distance matrices - for partitioning distance matrices among
sources of variation and fitting linear models (e.g., factors,
polynomial regression) to distance matrices; uses a permutation test
with pseudo-F ratios.

#### [Questions:]{style="color:forestgreen"}

#### [30.1 What do the results from anosim and adonis tell you?]{style="color:forestgreen"}

#### [30.2 Give one other example of predefined groups that could be used as the grouping variable(s)!]{style="color:forestgreen"}

```{r}
# Start with a CA with Management as environmental factor and hulls around the different management types
dune.ca <- cca(dune)
fit.mgm <- envfit(dune.ca ~ Management, dune.env.original, perm = 0)
plot(dune.ca, type = "n", scaling = "symmetric")
with(
  dune.env.original,
  points(
    dune.ca,
    display = "sites",
    scaling = "symmetric",
    col = as.numeric(Management),
    pch = 16
  )
)
with(
  dune.env.original,
  ordispider(dune.ca, Management, scaling = "symmetric", col = "skyblue")
)
with(dune.env.original,
     ordihull(dune.ca, Management, scaling = "symmetric", label = TRUE))

dune.dist <-
  vegdist(dune, method = "bray") #create distance matrix based on Bray-Curtis method
dune.ano <-
  anosim(dune.dist, dune.env.original$Management) #Comparing groupings based on management
summary(dune.ano)
plot(dune.ano, xlab = "Anosim, Dune meadow management types") #note the error message here:
#notches are used in box plots to help visually assess whether the medians of distributions #differ. If the notches do not overlap, this is evidence that the medians are different.Here #the confidence region (the notch) went past the bounds (or hinges) of one of the boxes. 

#ANOSIM gives you the P value and a R value. R value close to 1 indicates high separation between levels of your factor while R value #close to 0 indicate no separation between levels of your factor.

```

Also try the recommended alternative "adonis" - Analysis of variance
using distance matrices - for partitioning distance matrices among
sources of variation and fitting linear models (e.g., factors,
polynomial regression) to distance matrices; this uses a permutation
test with pseudo-F ratios. We can also do pairwise comparisons to see
which groups differ from each other.

```{r}
dune.ado<-adonis2(formula = dune~Management, data = dune.env.original, method = "bray")
dune.ado

# You can also have more advanced models in adonis
dune.ado2<-adonis2(dune~Management*A1, data = dune.env.original)
dune.ado2

```

The adonis test tells us that there is a difference between our grouping
factors, but the pairwise test can tell us exactly which pairs of groups
differ from each other. Note that this only makes sense if the overall
test is significant!

#### [30.3 Which pairs of groups significantly differ from each other?]{style="color:forestgreen"}

```{r}
# Run the pairwiseAdonis function

pairwise.adonis2(dune~Management, data = dune.env.original)
```

After a significant ANOSIM or PERMANOVA, you may want to know which
species are primarily responsible for the observed difference between
clusters. SIMPER (Similarity Percentage) will do this for you. The test
gives by-species p values for changes in abundance, but does not do
significance testing for overall difference between groups. In the
output tables, taxa are sorted in descending order of contribution to
group difference. Consider those contributions (effect sizes), not just
the p values - statistically significant does not mean ecologically
important! Especially if you have a large dataset, you may find some
small differences that are probably ecologically unimportant
nevertheless yield a p value under 0.05...

#### [30.4 Compare the different groups and check which species contribute mostly to the difference between pairs of clusters.]{style="color:forestgreen"}

In the output there are columns for "ava" and "avb". As you may suspect,
these are average abundances of the species in group A and group B.

```{r message=FALSE, warning=FALSE}
sim <- simper(dune, dune.env.original$Management) #try management groupings
summary(sim)
```

Visually compare the result from simper with species positions in a
biplot.

```{r}
plot(dune.ca, type = "n", scaling = "species")
with(dune.env.original, points(dune.ca, display = "sites", scaling = "species", col = as.numeric(Management), pch=16))
with(dune.env.original, orditorp(dune.ca, display = "species", scaling = "species"))
with(dune.env.original, ordihull(dune.ca, Management, scaling = "species",label = TRUE))
```

A complementary/alternative approach to identifying which species are
most responsible for the differences between the groups is that of
indicator species - which species best characterise the groups or
clusters that we have identified?

In this exercise we will investigate if any particular species are
indicative for the four different management types.

#### [30.5 Use the resulting data table to find the two top indicator species for each of the four Management types!]{style="color:forestgreen"}

```{r, warning=FALSE, message=FALSE}
iva <- indval(dune, dune.env.original$Management) #this time we don't need dummy variables for management
iva.df <- as.data.frame(iva$indval)
#arrange in descending order to find best indicator species, change BF to other management types as needed
dplyr::arrange(rownames_to_column(iva.df), desc(HF))
```

------------------------------------------------------------------------

------------------------------------------------------------------------

### [Exercise 31: DFA]{style="color:cornflowerblue"}

The algorithm starts by finding directions that maximize the separation
between classes, then use these directions to predict the class of
individuals. These directions, called linear discriminants, are linear
combinations of predictor variables. The Dune dataset is too small to
really make use of this method (since we need to split the data into
test and training parts) so we will here use the classic "Iris" dataset
of different Iris plant species and the dimensions of different parts of
their flowers

#### [Questions:]{style="color:forestgreen"}

#### [31.1 How well does the algorithm distinguish between the species?]{style="color:forestgreen"}

#### [31.2 Here our groups are pre-defined (species). Would it be OK to use one of the clustering methods to find groups before running the DFA?]{style="color:forestgreen"}

```{r DFA}
# Load the data
data("iris")

# Split the data into training (80%) and test set (20%)
set.seed(123)
training.samples <- iris$Species %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data <- iris[training.samples,]
test.data <- iris[-training.samples,]

# Discriminant analysis can be affected by the scale/unit in which predictor variables are measured. 
# Itâ€™s generally recommended to standardize/normalize continuous predictor before the analysis.
# Normalize the data. Categorical variables are automatically ignored.
# Estimate preprocessing parameters
preproc.param <- train.data %>%
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

# Linear discriminant analysis - LDA ####
# Fit the model
model <- lda(Species ~ ., data = train.transformed)

model
plot(model, dimen = 1)#, type="both")
```

LDA determines group means and computes, for each individual, the
probability of belonging to the different groups. Each
observation/individual is then assigned to the group with the highest
probability score.

The lda() outputs contain the following elements:

Prior probabilities of groups: the proportion of training observations
in each group. For example 33% of the training observations are in the
Setosa group.

Group means: group center of gravity. Shows the mean of each variable in
each group.

Coefficients of linear discriminants: Shows the linear combination of
predictor variables that are used to form the LDA decision rule. If the
predictor variables are standardized before computing LDA, the
discriminator weights can be used as measures of variable importance for
feature selection.

Using the function plot() produces plots of the linear discriminants,
obtained by computing LD1 and LD2 for each of the training observations.

```{r}
# Make predictions
predictions <- model %>% predict(test.transformed)
# Model accuracy
mean(predictions$class==test.transformed$Species)

# The predict() function returns the following elements:
#   
# class: predicted classes of observations.
# posterior: is a matrix whose columns are the groups, rows are the individuals and values are the posterior probability that the corresponding observation belongs to the groups.
# x: contains the linear discriminants, described above

# Predicted classes
head(predictions$class, 6)
# Predicted probabilities of class membership.
head(predictions$posterior, 6) 
# Linear discriminants
head(predictions$x, 3) 

lda.data <- cbind(train.transformed, predict(model)$x)
#lda.data <- cbind(test.transformed, predictions$x)
ggplot(lda.data, aes(LD1, LD2)) +
  geom_point(aes(color = Species),size=3)+
  scale_colour_manual(name="",  
                      values = c("setosa"="blue", "versicolor"="orange", "virginica"="black"))

# Model accuracy
mean(predictions$class==test.transformed$Species)

#More detailed assessment (probably more information than we need!)
#Calculates a cross-tabulation of observed and predicted classes with associated statistics.
confusionMatrix(test.data$Species, predictions$class)

```

------------------------------------------------------------------------

### [Exercise 32: Classification 2: Partition and Regression Trees]{style="color:cornflowerblue"}

Most of the code is taken from
<https://jonlefcheck.net/2015/02/06/a-practical-guide-to-machine-learning-in-ecology/>
Here, we will use the iris data. This is a "classic" data set used for
exploring multivariate methods for
discrimination.<https://en.wikipedia.org/wiki/Iris_flower_data_set>

#### [Questions:]{style="color:forestgreen"}

#### [32.1 Based on a visual analysis, which dimensions provide the best separation between iris species?]{style="color:forestgreen"}

#### [32.2 Are your insights from the visual analysis confirmed by the partition tree analysis?]{style="color:forestgreen"}

#### [32.3 Does the partition tree provide a perfect species identification or are there misclassifications?]{style="color:forestgreen"}

```{r}
# Before starting the analysis, we will generate pairwise scatterplots of the data
#
# the following line will first check to see inf the "psych" library is loaded, and only 
# load it if it is not present
#
if(!is.element("psych",installed.packages()[,1])) {install.packages("psych") }
library(psych)
library(rpart)
library(rpart.plot)
#
# create pairwise plots of the variables in the iris data set
#
pairs.panels(iris[,-5],gap=0,bg=c("red","blue","yellow")[iris$Species],pch=21)
#
# what does rpart() do ?
#
help(rpart)
#
# set up the partition tree model for the iris data
#
iris.tree.model<-rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
# 
# display the partition tree
#
rpart.plot(iris.tree.model, extra=0, box.palette =list("red", "blue", "forestgreen"))

#
# plots for confirmatory visual analysis
#
plot(iris$Petal.Length, col = c("red", "blue", "forestgreen")[iris$Species], xlab = "", ylab = "Petal Length (cm)")
legend(120, 2, c("setosa","versicolor","virginica"), col = c("red", "blue", "forestgreen"), pch = 0.7)
abline(h = 2.45)
#
plot(iris$Petal.Width, col = c("red", "blue", "forestgreen")[iris$Species], xlab = "", ylab = "Petal Width (cm)")
legend(20, 1.5, c("setosa","versicolor","virginica"), col = c("red", "blue", "forestgreen"), pch = 0.7)
abline(h = 1.75)
```

------------------------------------------------------------------------

### [Exercise 33: Model based ordination]{style="color:cornflowerblue"}

Dissimilarity-based ordination methods begin by calculating a
dissimilarity or distance matrix between sites (or more generally,
observational units). Afterwards, these are collapsed to a small number
of dimensions for plotting using an algorithm that attempts to preserve
and display information about these relative distances. The model-based
approach explicitly specifies a statistical model of the process that
generated the observed data. Model-based ordination methods (mostly) use
an extension of generalised linear mixed models known as latent variable
models. As the name suggests, these models account for the correlation
between taxa via the inclusion of a small number of latent variables.
Latent variables act as natural ordination axes reflecting unobserved
covariates.

#### [Question:]{style="color:forestgreen"}

#### [33.1 How do the ordinations produced compare to a distance based ordination (for example an NMDS) of the same species data?]{style="color:forestgreen"}

```{r}
#load species abundance data
spe<-as.data.frame(read_xlsx("Data/dune.xlsx", na = ".",sheet = 1, col_names = TRUE)); spe[1]<-NULL
#we need to provide the model with an appropriate probability distribution for the data.
#Given our abundance data is on a scale of 1 - 9 we could classify it as ordinal data,
#but we can try another distribution as well to compare results.

fitnb <- gllvm(y = spe, family = "negative.binomial") #This takes a minute or so to run!
fitord <- gllvm(y = spe, family = "ordinal", zeta.struc = "common")
#ignore the warning messages generated for now!

#As with "normal" linear regressions we can check model fit with widely used tools like
#Akaike Information Criterion (AIC). AIC aims to select the model which best explains 
#the variance in the dependent variable with the fewest number of independent variables
#So it helps select a simpler model over a complex model, if the complexity is not helpful.
#A lower AIC is better!

AIC(fitnb)
AIC(fitord)

#It seems the ordinal model is the best.
```

We can also use graphical checks of model fit, as with any regression.
If you are familiar with these try running plot(fitord) and plot(fitnb).

Now we can look at the ordination plot for the best model.

```{r}
par(mfrow = c(1, 2))
ordiplot.gllvm(
  fitord,
  main = NULL,
  biplot = T,
  s.colors = "black",
  spp.colors = "blue",
  alpha = 0.45,
  cex.spp = 0.7,
  jitter = F,
  s.cex = 0.6
)

abline(h = 0, v = 0, lty = 2)
#compare with an NMDS
distord <- metaMDS(spe)
vegan::ordiplot(distord, type = "t")
par(mfrow = c(1, 1))
```

We can do a lot more with model based ordinations, including
incorporating environmental variables. We can also include information
on traits and perform a fourth corner analysis.

------------------------------------------------------------------------

### [Exercise 34: Fourth Corner]{style="color:cornflowerblue"}

Here we will use another model based method (the "mvabund" package for
analysing multivariate abundance data) to perform a fourth corner
analysis. That is to say we will include trait information and
environmental variables, and investigate the relationship between plant
traits and environmental variables.

#### [Question:]{style="color:forestgreen"}

#### [34.1 Do the correlations in the plot make sense ecologically?]{style="color:forestgreen"}

```{r}
# Read and treat data

env<-as.data.frame(read_xlsx("Data/dune_env.xlsx", na = "NA",sheet = 1, col_names = TRUE)); env[1]<-NULL
env$Management<-as.factor(env$Management)
env$Use<-as.factor(env$Use)
#This is from a database of plant traits
traits<-as.data.frame(read_xlsx("Data/TylerTraits.xlsx", na = "NA",sheet = 1, col_names = TRUE, skip = 1))
rownames(traits)<-traits$Spe; traits$Spe<-NULL 
names(traits)
traits<-traits[,-c(1:6,22, 27,29,30:32)] # Remove trait not feasible for this analysis
```

**Fourth corner analysis**

Given that there are many traits and even environmental factors that are
not strong predictors of abundance, we can reduce the number of
#predictor terms in our models.LASSO is an optimization algorithm (Least
Absolute Shrinkage and Selection Operator) that is used in this case.

```{r}

fitfourth = traitglm(spe, env, traits, method = "glm1path")
fitfourth$fourth #examine fourth corner terms, you may want to convert to a dataframe for further analysis
#View(as.data.frame(fitfourth$fourth))

#and plot the results
a        = max(abs(fitfourth$fourth.corner))
colort   = colorRampPalette(c("blue", "white", "red"))
plot.4th = levelplot(
  t(as.matrix(fitfourth$fourth.corner)),
  xlab = "Environmental Variables",
  ylab = "Species traits",
  col.regions = colort(100),
  at = seq(-a, a, length = 100),
  scales = list(x = list(rot = 45))
)
print(plot.4th)

#Goodness of fit check - do the points lie mostly along the diagonal line? If not you may have a problem!
qqnorm(residuals(fitfourth)); abline(c(0,1),col="red") # for a normal quantile plot.


```

We can also test for significance and explore the effects of individual
trait by environment interactions using the summary() function of the
mvabund package. Warning! This code is commented out as it is very slow
to run with this many traits and environmental variables, even with a
limited number of iterations. Don't run this code chunk unless you want
to take a rather long coffee break! If this is something you do want to
do, narrow down the focus to fewer traits and environmental factors,
using only those you are really interested in.

```{r}
#We can test for overall significance using an anova (only on default manyglm model, 
#not available for Lasso model). This is a bit slow, but only several minutes.
#fitfourth2 = traitglm(spe, env, traits)
#pvalues <- anova.traitglm(fitfourth2,nBoot=20) #overall significant

#INDIVIDUAL TRAITS#
#We will limit the number of bootstrap reps to 5 (nBoot=5) but at least several hundred should be used for reliable results/final analyses. Given how slow this is with nBoot=5, I guess this would take many hours

#summary(fitfourth2, resamp = "montecarlo", nboot=5)

#Example of output if you don't want to wait for the code to run...

#UsePasture.N_fix1           0.467     0.115    

#The numbers returned are a test statistic and a P-value calculated by resampling rows of the data. In this case the interaction is not significant (p=0.115)
```

------------------------------------------------------------------------
