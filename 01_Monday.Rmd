---
title: "Monday"
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(vegan)
library(tidyverse)
library(corrplot)

```

### [Exercise 1. Introduction to R Notebooks and Markdown.]{style="color:cornflowerblue"}

This exercise is only to get used to working with R Notebook/R Markdown. The data in this first exercise are not multivariate and the statistical analysis is a simple linear regression. All following exercises will start with this kind of introduction.

### [For each exercise there will be a number of explicit questions written in green.]{style="color:forestgreen"}

To pass the course, you should give your answers to these questions to one of the teachers during the computer labs.

#### [If you find it useful, you can write your answers to the questions and any other comments or notes using the Answers.Rmd file as a template, but you are free to create a new file yourself, modify your local copy of the exercises or do whatever works for you!.]{style="color:Red"}

------------------------------------------------------------------------

#### A quick note on R Notebooks and R Markdown

These terms are often used interchangeably to mean a combination of R code, results, and formattable text, such as this one. They allow you to present your results, the code used to generate the results and your interpretation and comments all together in one document that you can easily update, and which is easy for a reader to understand (R Notebooks are a minor update of R Markdown files that allow for easier editing as you can run just part of your code and see the results in a preview. Both notebook and markdown are .Rmd files, and are written in exactly the same way, so don't worry about the difference for this course!).

------------------------------------------------------------------------

#### Example of a simple analysis

First we load or create the data we will be using. The box below is an example of a code chunk.

```{r}
df <- read.table(header = TRUE, sep = ",", 
               text = "x,y 
               1,2
               1.5,3.5
               2,5
               2.5,5
               3,7")

# Anything you write in a code chunk after a hash mark becomes a comment like this
# and is ignored when running the code. If you are working in an R markdown notebook
# such as this however, you can also write your longer notes in the text sections 
# outside the code chunks.
```

So I could write my notes here instead, which is probably easier to read for anything more than a few words of explanation.

Now we can do a simple linear regression, using variables x and y in the dataset called df. The results are stored in the object "reg". There is no output from this chunk as we have not asked for it. We only get the object "reg".

```{r}
reg <- lm(y~x, df) 
```

To get an output, you can ask for a summary of "reg"

```{r}
summary(reg)
```

Make a scatter plot of y as a function of x, and use the object "reg" to draw a regression line.

```{r}
plot(y~x, df)
lines(df$x, predict(reg), col = 'red') # Add a regression line to the plot
```

### [The R packages and data we will be using.]{style="color:cornflowerblue"}

The "dune" dataset we will use is included in the vegan package (an extensive collection of tools for multivariate analysis). The dune data consists of one file with species abundance in sampling plots, and one file with environmental (also called explanantory) data for the same monitoring plots.

We will also be using some slightly modified and extended versions of the dune data, which we will load as needed. We will also load some other packages to extend the range of analyses available to us.

------------------------------------------------------------------------

### [Exercise 2: Simple exercise for illustrating effects of different distance metrics.]{style="color:cornflowerblue"}

All methods you will meet this week are based on similarities or dissimilarities among your objects. These can be calculated in many different ways. Here, we will create a simple data set consisting of 2 columns of measurement made on 3 objects (or sites). We will then calculate a series of distance metrics using the vegdist() function.

#### [Questions:]{style="color:forestgreen"}

#### [2.1 How do the metrics differ (conceptually, not a detailed mathematical explanation)?]{style="color:forestgreen"}

#### [2.2 Which metric corresponds to a geographic distance]{style="color:forestgreen"}, and which to a species community distance?

```{r message=FALSE, warning=FALSE}
# create a triangular data set with 2 columns (x and y) and 3 rows
#
dt <- data.frame(x = c(5, 5, 10, 0), y = c(5, 10, 10,0))
#plot dt
plot(dt, xlim = c(0, 15), ylim = c(0, 15))
# what does vegdist() do?
#
help(vegdist)
#
# create some distance matrices with using different metrics
#
(dt.bray <- vegdist(dt, method = "bray"))
(dt.euclidean <- vegdist(dt, method = "euclidean"))
(dt.hellinger <- vegdist(dt, method = "hellinger"))

```

------------------------------------------------------------------------

### [Exercise 3: In this exercise we will use Principal Components Analysis on the dune meadow explanatory data. We will also explore the effects of different kinds of scaling on the ordination plot. NOTE that the scaling issues applies to all ordination techniques!]{style="color:cornflowerblue"}

Compare the plots on the PCA with and without scaling (PCA plot 4) and discuss the differences.

#### [Questions:]{style="color:forestgreen"}

#### [3.1Why is there a difference between the two plots in "PCA plot 4" ? Which one is best to use?]{style="color:forestgreen"}

#### [3.2 Is there any way to see if a PCA plot is based on scaled or unscaled data, just by looking at the plot?]{style="color:forestgreen"}

#### [3.3 Why is there a difference between the plots in plot 5? Which one is best to use?]{style="color:forestgreen"}

First we load the Dune vegetation data we will use and clean it up a little.

```{r}
data("dune") # the dune species data
data("dune.env") # the dune explanatory data
dummy_management <-
  as.data.frame(model.matrix(~ Management - 1, data = dune.env))
#add these to the dataset
dune.env.original <-
  dune.env #we keep a copy of the original version
dune.env <-
  dune.env %>% select(A1, Moisture, Manure, Use) %>% cbind(., dummy_management)
dune.env$Moisture <-
  as.numeric(as.character(dune.env$Moisture)) #make numeric
dune.env$Manure <- as.numeric(as.character(dune.env$Manure))
dune.env$Use <- as.numeric(dune.env$Use)
#make column names shorter
dune.env <-
  dune.env %>% rename(BF = ManagementBF,
                      HF = ManagementHF,
                      NM = ManagementNM,
                      SF = ManagementSF)
```

Start by looking at pairwise correlations among the variables.

```{r}
#Plot 1
dune.env_cor <- cor(dune.env, method = "kendall")
corrplot(
  dune.env_cor,
  type = "upper",
  order = "hclust",
  tl.col = "black",
  tl.srt = 45
)
```

Next we do some PCA analyses and plot the results

```{r, warning=FALSE, message=FALSE}
## PCA plot 2:
# Then make a PCA, with scaling of (=standardising) the data
env.pca <-
  pca(dune.env, scale = TRUE) 
biplot(env.pca, main = "Plot 1") #plot the results using the default plot scaling which is "species"
env.pca #summarise results
summary(eigenvals(env.pca)) #see variance explained

## PCA plot 3:
# Continue with a PCA on the same data, but without scaling of the data
env.pca2 <-
  pca(dune.env, scale = FALSE) 
biplot(env.pca2, main = "Plot 2")#plot the results
env.pca2 #summarise results
summary(eigenvals(env.pca2)) #see variance explained

```

It can often be useful to put plots side by side to compare the results

```{r}
## PCA plot 4:
# Put plot 2 and 3 beside each other
# Default scaling of the plots, which is "species"
par(mfrow = c(1, 2)) #This puts the plots below in 1 row and two columns
biplot(env.pca, main = "PCA, with scaling of data")
biplot(env.pca2, main = "PCA, without scaling of data")
par(mfrow = c(1, 1)) # Restore the plot settings to one plot at the time

## PCA plot 5:
# Plots from the same PCA, but with plot scaling focused on sites and on species
par(mfrow = c(1, 2))
biplot(env.pca, scaling = "sites", main = "PCA, plot scaling on sites")
biplot(env.pca, scaling = "species", main = "PCA, plot scaling on species")
par(mfrow = c(1, 1))

## PCA plot 6:
# Same as plot 6, but without species for better visual inspection of the sites
par(mfrow = c(1,2))
biplot(env.pca, scaling = "sites", display = "sites", main = "Plot scaling on sites")
biplot(env.pca, scaling = "species", display = "sites", main = "Plot scaling on species \n not correct projection of sites")
par(mfrow = c(1,1))
# In this case there are only minor differences between the two plots
```

------------------------------------------------------------------------

### [Exercise 4: Investigate the axes in the PCA in Question 3]{style="color:cornflowerblue"}

Here we will learn that only looking at a ordination plot or the basic numerical output may not be sufficient to tell if the ordination axes are interpretable in terms of expressing a latent gradient.

#### [Questions:]{style="color:forestgreen"}

#### [4.1 Look at the loadings (=species scores), i.e. the effects by the different variables for axis 1 and axis 2. Which variables are most important?]{style="color:forestgreen"}

```{r, warning=FALSE, message=FALSE}
# We can look at the effects by individual variables
loadings <- scores(env.pca, display = 'species', scaling = 0)
sort(abs(loadings[,1]), decreasing = TRUE) # Loadings axel 1
sort(abs(loadings[,2]), decreasing = TRUE) # Loadings axel 2

```

As you saw in the lecture, you can also run approximate significance tests for a PCA. You can do this with e.g. the BiodiverityR package, but unfortunately we are unable to install that in the Posit Cloud environment (because it requires installing things in the underlying operating system as well as in R). We can anyway draw an Equilibrium Contribution Circle, by adding the equations for the circle in our code. This defines a region beyond which variables can be interpreted with greatest confidence.

#### [4.2 Which variables are unimportant for the for the two-dimensional projection of your sites along axis 1 and 2?]{style="color:forestgreen"}

```{r, warning=FALSE, message=FALSE}
# Equilibruium Circle 
biplot(env.pca, scaling="species", main="Scaling = species")
d <- 2 # Two axes plotted (axis 1 and axis 2)
p <- ncol(dune.env) # Number of descriptors
radi <- sqrt(d/p)

circ <- seq(0,2*pi,length=100)
coords <- t(rbind(sin(circ)*radi, cos(circ)*radi))
lines(coords, col="blue")
```

------------------------------------------------------------------------

### [Exercise 5: Do a CA-ordination on the Dune Meadow species dataset. What are the results telling you?]{style="color:cornflowerblue"}

#### [Question:]{style="color:forestgreen"}

#### [5.1 Give a conceptual description of why objects/samples and descriptors/species to the left differ from objects and descriptors to the right, and those at the bottom from those at the top!]{style="color:forestgreen"}

#### [5.2 Can you see an edge effect (a mathematical artifact that compresses the samples at one or both ends of a gradient)?]{style="color:forestgreen"}

#### [5.3 Can you see an arch effect?]{style="color:forestgreen"}

```{r, warning=FALSE, message=FALSE}
dune.ca <- ca(dune)
plot(dune.ca)
dune.ca
summary(eigenvals(dune.ca)) #proportion variance explained
```

------------------------------------------------------------------------

### [Exercise 6: Repeat exercise 5, but with DCA ordination instead.]{style="color:cornflowerblue"}

#### [Question:]{style="color:forestgreen"}

#### [6.1 If you found artifacts in the CA in question 5, did the detrending remove them?]{style="color:forestgreen"}

#### [6.2 Look at the eigenvalues, the length of gradient, the total variation and the ordination diagram. Explain the differences between results from CA and DCA.]{style="color:forestgreen"}

Note that we do not get "variation explained" in the R implementation of DCA (and some other functions). The developer of the vegan package explains: "*The total amount of variation is undefined in detrended correspondence analysis and therefore proportions from total are unknown and undefined. DCA is not a method for decomposition of variation, and therefore these proportions would not make sense either.*"

```{r, warning=FALSE, message=FALSE}
#Detrended correspondence analysis (function decorana).
dune.dca <- decorana(dune)
dune.dca 
plot(dune.dca)
```

------------------------------------------------------------------------
