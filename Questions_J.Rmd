---
title: "MVA Course"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

First we need to load the R packages we will be using and import the data. The "dune" dataset is included in the vegan package (an extensive collection of tools for multivariate analysis), but we will be using a slightly modified and extended version of it. In the excercises you may notice that the results returned are sometimes slightly different to those produced by the various graphical interface applications used (Canoco/PAST/Simca). This is a result of different opinions about the best way to implement various design decisions, but the overall patterns seen and the significance of results will be very similar.

```{r message=FALSE, warning=FALSE}
library(vegan)# Package for multivariate analyses of ecological data
library(dplyr)# Package for data transformation

#Lets's load the data, which is packaged as an RDS object
load("MVM_data.RDS")

#change names to match what is seen in Canoco based presentations 
dune.env <- EnvVar
dune <- Species


#Management factor is character data but we need it to be numeric data for some analyses. Convert to "dummy" variables...
#Note:If you are converting a factor that is numeric already you need as.numeric(as.character(x))

#We need to give each management method its own column
dummy_management <- as.data.frame(model.matrix( ~ Management - 1, data=dune.env )) 
#add these to the dataset
dune.env.original <- dune.env
dune.env <- dune.env %>% select(A1, Moisture, Manure, Use) %>% cbind(.,dummy_management) 
dune.env$Moisture <- as.numeric(as.character(dune.env$Moisture)) #make numeric
dune.env$Manure <- as.numeric(as.character(dune.env$Manure))
dune.env$Use <- as.numeric(dune.env$Use)
#make column names shorter
dune.env <- dune.env %>% rename(BF = ManagementBF, HF = ManagementHF,
                                NM = ManagementNM, SF = ManagementSF)
```
***
#### Question 2: Do a PCA on the environmental data related to the Dune meadow dataset.
What are the results telling you? In what way do objects/samples to the left differ from objects to the right, and at the bottom from those at the top? Which are the most important gradients in the dataset? Which descriptor variables are related, and which are unrelated? 

```{r}
env.pca <- rda(dune.env, scale = TRUE) #vegan uses the same function for PCA and RDA, just depends on if it is constrained or not.
biplot(env.pca)#plot the results
env.pca #summarise results
summary(eigenvals(env.pca)) #see variance explained
```
***
#### Question 3: For comparison, do also a CA on the Dune Meadow Environmental variables and compare the result with the PCA on the same data! 

Why do the results in exercise 2 and 3 differ?

```{r}
#unconstrained ordination on environmental data (CA)
env.ca <- cca(dune.env) #vegan uses the same function for CA and CCA
plot(env.ca)
env.ca
summary(eigenvals(env.ca)) #proportion variance explained
```
***
#### Question 4: Do a CA-ordination on the Dune Meadow species dataset.What are the results telling you? 

Give a conceptual description on why objects/samples and descriptors/species to the left differ from objects and descriptors to the right, and those at the bottom from those at the top! (Plant ecologists may give a more detailed description, using their knowledge about the species in the dataset).
```{r}
dune.ca <- cca(dune)
plot(dune.ca)
dune.ca
summary(eigenvals(dune.ca)) #proportion variance explained
```
***
#### Question 5: Repeat exercise 4, but with DCA ordination instead. 

Look at the eigenvalues, the length of gradient, the total variation and the ordination diagram. 
Explain the differences between results from CA and DCA.

```{r}
dune.dca <- decorana(dune)
dune.dca 
#Detrended correspondence analysis (function decorana).
#The total amount of variation is undefined in detrended 
#correspondence analysis and therefore proportions from total
#are unknown and undefined. 
#DCA is not a method for decomposition of variation, and therefore
#these proportions would not make sense either.

plot(dune.dca)

```

#### Question 21: Interpreting ordination results using species traits

Experienced plant ecologists may already have looked at the species in the Dune Meadow ordination graphs and concluded that species with similar traits occur together. This is possible if you have good knowledge about plant species ecological preferences, and if there are relatively few species in your dataset. In this exercise we will use tabulated data on species ecological preferences (the Ellenberg indicator values) to interpret the results of the ordinations. The Ellenberg indicator values are described on the first page in this booklet. Which Ellenberg values are most important for the distribution of the species? What do the different axes represent in terms of environmental gradients?

```{r}
#rename data with Ellenberg values to match Canoco based presentations

dune.ell <- Ellenberg
dune.mean.ell <- Mean_Ellenberg

#The vegan implementation of forward selection of variables does not accept NA values.
#To get around this we will replace the two NAs with the mean value for all plots in that column.
#Do not do this in a real analysis without seriously thinking about how it affects your results!
#This also means that the ordinations you produce may look very slightly different to those produced in Canoco, 
#but the overall patterns and significance of results will be the same.


## Code to replace missing values with the column mean, and save the results as a new dataframe
## called dune.mean.ell.impute (since we are imputing the missing values).

dune.mean.ell.impute <- data.frame(
    sapply(
        dune.mean.ell,
        function(x) ifelse(is.na(x),
            mean(x, na.rm = TRUE),
            x)))


#CCA analysis
#create global model with CCA (including all variables) and test it's significance, and if it is significant,
#we use the ordistep function with appropriate arguments to do forward selection of variables.
cca1 <- cca(dune ~ ., data = dune.mean.ell.impute) # full model (with all explanatory variables)
anova(cca1) #overall model is significant
adjR2.cca <- RsquareAdj (cca1)$adj.r.squared 

# Start by making ordinations
cca0 <- cca (dune~ 1, data = dune.mean.ell.impute) # empty model only with intercept
cca1 <- cca(dune ~ ., data = dune.mean.ell.impute, na.action = na.omit) # full model (with all explanatory variables)
cca1
plot(cca1, main="CCA, all data")

#Stepwise approach, using "ordistep"
step2<-ordistep(cca0, scope = formula(cca1), perm.max=9999)
step2$anova # N F T L S sig


# New model with only significant explanatory variables?
cca3 <- cca(dune ~ N + F + T + L + S, data = dune.mean.ell.impute)
cca3
ordiplot(cca3, main = "CCA, significant variables only", type = "text")


```

#### Question 22: Decomposition of variance

In usual analysis of variance experiments, the variance is decomposed into components. The same can be done in multivariate analyses. In this exercise you will decompose the variance in the Dune meadow data set into different variance components. You will use two groups of variance components: Group 1 is Management and Group 2 is the soil variables (A1 and Moisture). In ordinations, the variance is expressed by the sum of the eigenvalues. 

The result gives you the fraction of the total variation that is explained by:
    a) uniquely by Management (effect of soil removed),
    b) uniquely by soil (effect of Management removed),
    c) jointly by Soil and Management (the interaction).
    
The total explained variation is the sum of a), b) and c). 

The total variation in the dataset is the sum of all unconstrained eigenvalues.


Perform the analyses and interpret the results!
How much of the total variation (% of All) is explained by:
- uniquely by Management (effect of Soil removed),
- uniquely by Soil  (effect of Management removed),
- jointly by Soil and Management (the interaction)
- Not by Soil or Management?


```{r}
## variance partitioning

management <- dune.env[,c("BF", "HF", "NM", "SF")]
soil <- dune.env[,c("A1", "Moisture")]
# examine the explanatory variable of each class of variables.
varp <- varpart(dune, management, soil)


#varp2 <- varpart (dune, ~ BF + HF + NM + SF,
# ~ A1 + Moisture, data = dune.env)
varp
plot (varp, digits = 2, Xnames = c('Management', 'Soil'), bg = c('red', 'blue'))
```


#### Question 23: Diagnostic species for a priori defined groups
In this exercise we will investigate if any particular species are indicative for the four different management types. The CANOCO version of this analysis is a simplified version of these types of tests. The full versions also give significance testing and more comprehensive result presentations. See for instance IndVal by Dufresne & Legendre.
    1. Go to menu Data /Add new table(s) / Indicator values.
    2. Mark the Species data table, and Management as the factor defining groups.
    3. Opt for Indicator Value (quantitative). 
    4. Export the table to Excel to be able to sort the data to find the highest values = best indicators for a group.
Use the resulting data table to find the two top indicator species for each of the four Management types!

```{r}
library(labdsv)
library(tibble)

iva <- indval(dune, dune.env.original$Management) #this time we don't need dummy variables for management

iva.df <- as.data.frame(iva$indval)
#arrange in descending order to find best indicator species, change BF to other management types as needed
arrange(rownames_to_column(iva.df), desc(HF))

#or create dataframe of best results for each management
#gr <- iva$maxcls[iva$pval<0.1]
#iv <- iva$indcls[iva$pval<0.1]
#pv <- iva$pval[iva$pval<0.1]

#indvalsummary <- data.frame(group=gr, indval=iv, pvalue=pv)
#indvalsummary <- indvalsummary[order(indvalsummary$group, -indvalsummary$indval),]
#indvalsummary

```


#### Question 24: Analysing a time series with vegetation data

Quite often vegetation ecologists have data from repeated inventories in permanent plots. The overall question to answer is if there has been a significant and directional change in the species composition. In this exercise we have rearranged the Dune Meadow data so that it consists of only 10 plots, each analysed 2 times (same species as in all other exercises, just grouping and rearrangement of plots). We want to analyse if there has been a consistent change in species composition between the two inventories. We are thus not interested in differences between the ten plots. 


```{r}
#This partials out the effect of Plot before analysing the effects of Time

time.cca <- cca(SpeTS ~ Time + Condition(Plot), data=EnvTS)
time.cca


treat <- EnvTS$Time #

colvec <- c("red2", "green4") #set colours to be applied to different levels of factor "Time"

plot(time.cca, type = "n", display = c("lc"))#plots the axes

with(time.cca, points(time.cca, display = c("lc"), col = colvec[treat],#plots the points
                      pch = 21, xlim = c(-2,2), bg = colvec[treat]))




```

```{r}
#permutation test
with(EnvTS, anova(time.cca, by="term", perm=500, strata=Plot))
```



```{r}
#Compare with results for time as only explanatory variable and no cofactors
time2.cca <- cca(SpeTS ~ Time, data=EnvTS)
time2.cca
#permutation test
with(EnvTS, anova(time2.cca, by="term", perm=500, strata=Plot))

```



```{r}

## plot ellipsoid hulls

treat <- EnvTS$Time

plot(time2.cca, type = "n")#plots the axes
with(time2.cca, points(time2.cca, col = colvec[treat],#plots the points
                      pch = 21, bg = colvec[treat]))
ordihull(time2.cca,groups=treat,draw="polygon",col="grey70",label=T)#draw hulls around area of each level of factor "Time"
```

#### Question 25: A multivariate Before-After-Control- Impact (BACI) study


In this exercise we will continue to use the rearranged Dune Meadow data from exercise 24. A difference is that the plots are now divided into four groups:
    1. Control plots before a treatment (i.e. not treated)
    2. Control plots after a treatment (i.e. not treated)
    3. Impact plots before treatment (i.e. not treated)
    4. Impact plots after treatment (this is where the treatment is made)

The four groups are indicated in variable Treat in the environmental data set (EnvTS).
The question you want to answer is if the treatment caused a change in species composition that is significantly different from the change in the control plots.

```{r}

baci.cca <- cca(SpeTS ~ Treat + Condition(Plot + Time), data=EnvTS)

baci.cca
```



```{r}
with(EnvTS, anova(baci.cca, by="term", perm=500, strata=Treat))
#Here with() is a special function that makes variables in dune.env visible to
#the following command. If you only type Moisture in an R prompt, you will get
#an error of missing variables
```




```{r}
## plot results

treat <- EnvTS$Treat
ordiplot(baci.cca,type="points")
ordihull(baci.cca,groups=treat,draw="polygon",col="grey70",label=T)#draw hulls around area of each level of factor "Time"


```



#### Question 26: SIMCA PLS STUFF
```{r}
data.pls <- Trend_Lakes_2015_PLS
#View(data.pls)

install.packages("pls")
library(pls)
#PLS regression, like PCA, seeks to find components which maximize the variability of predictors but differs from PCA as PLS requires #the components to have maximum correlation with the response. PLS is a supervised procedure whereas PCA is unsupervised.

pls.fit <- plsr(`Biovolym (mm3/l)` ~ ., data = data.pls[c(9:35)], scale = TRUE, validation = "CV")
pls.pred = predict(pls.fit, data.pls[1:5, ], ncomp=1:2)

#pcr.fit <- plsr(`Abs_F 420 (/5cm)` ~ ., data = data.pls[c(11:35)],scale = TRUE, validation = "CV")

#But how do we know from what number of predictors to choose? We can check the output of #summary(plsFit), which is truncated into two parts. We should look for component number which adequately explains both predictors and response variances.

#The first section displays the root mean squared error of prediction (RMSEP), cross-validation estimate, as well as the adj-CV, which #is adjusted for bias. Take note of the dimensions of X and Y of the data towards the top of the output.

#The next section shows the percent of variance explained by components for predictors and response. See how the variance explained #rises quickly from 1 component and stabilizes above 10..13 components. That would be a good component range for the pls model.



#PLS is a dimensionality reduction technique with some similarity to principal component analysis. The predictor variables are mapped #to a smaller set of variables, and within that smaller space we perform a regression against the outcome variable. In Principal #Component Analysis the dimension reduction procedure ignores #the outcome variable. However PLS aims to choose new mapped variables #that maximally explain the outcome variable.

#The next step is to remove unwanted variables and then build a model.  
#Cross validation is used to find the optimal number of retained dimensions.
#Then the model is rebuilt with this optimal number of dimensions. 
# Find the number of dimensions with lowest cross validation error
cv <- RMSEP(pls.fit)
best.dims <- which.min(cv$val[estimate = "adjCV", , ]) - 1
best.dims 

# Rerun the model
pls.fit2 <-  plsr(`Biovolym (mm3/l)` ~ ., data = data.pls[c(6:35)], ncomp = best.dims)

#Finally, we extract the useful information and format the output.
coefficients <-  coef(pls.fit2)
sum.coef <-  sum(sapply(coefficients, abs))
coefficients <-  coefficients * 100 / sum.coef
coefficients <-  sort(coefficients[, 1 , 1])
barplot(tail(coefficients, 5))

#The regression coefficients are normalized so their absolute sum is 100 and the result is sorted.

#The results below show that TPI and ? are positive predictors of Abs_F 436 (/5cm).  You could run the code #barplot(head(coefficients, 5)) to see that at the other end of the scale Siktdjup and pH are negative predictors.

summary(pls.fit2)
plot(pls.fit)
validationplot(pls.fit2, val.type = "MSEP")
predplot(pls.fit2)
coefplot(pls.fit2)


#summary(pcr.fit)
#plot(pcr.fit)
```


#### Question 27 : Classification

Start by testing the non-hierarchical K-means clustering, using Multivar / K-Means. Note that it is recommended that K-means need at least 100 observations (500 according to some sources) to be reliable! Let us ignore the sample size issue for the moment, and ask for 4 clusters (for later comparison with the four management types). Test different hierarchical agglomeration algorithms and similarity indices. Use at least the Euclidian and the Bray-Curtis similarity measures for the hierarchical clustering technique. Try also the Ward’s method! Repeat the analysis above, but copy the Management types to a new grouping column.

```{r}
# install.packages("dendextend")
library(dendextend)

dune.dist <- vegdist(dune, method = "bray")

# K-Means Cluster Analysis
fit <- kmeans(dune.dist, 4, nstart = 25) # 4 cluster solution
#As the final result of k-means clustering result is sensitive to the random starting assignments, we specify nstart = 25. This means #that R will try 25 different random starting assignments and then select the best results corresponding to the one with the lowest #within cluster variation. The default value of nstart in R is one. But, it’s strongly recommended to compute k-means clustering with #a large value of nstart such as 25 or 50, in order to have a more stable result.
table(fit$cluster, dune.env.original$Management)
# append cluster assignment
dune.clusters <- data.frame(dune, fit$cluster)
dune.clusters <- data.frame(dune.clusters, dune.env.original$Management)

#try some approaches to hierarchical clustering
dend <- dune %>% # data
        dist(method = "euclidean") %>% # calculate a distance matrix, 
        hclust(method = "ward.D") %>% # Hierarchical clustering 
        as.dendrogram # Turn the object into a dendrogram.
plot(dend)




```

#### Question 28: ANOSIM
ANOSIM (ANalysis Of Similarities) is a non-parametric test of significant difference between two or more groups, based on any distance measure. In this case, use the clusters from the K-means exercise. Change to Bray-Curtis similarity index.

What does the result tell you? What other types of predefined clusters could you use?


```{r warning=FALSE}
dune.dist <- vegdist(dune, method = "bray") #create distance matrix based on Bray-Curtis method

dune.ano <- anosim(dune.dist, fit$cluster) #compare groupings based on cluster analysis
dune.ano
plot(dune.ano)
title(sub = "Anosim, groups = cluster analysis")

#ANOSIM gives you the P value and a R value. R value close to 1 indicates high separation between levels of your factor while R value #close to 0 indicate no separation between levels of your factor.
```
```{r warning=FALSE}
dune.ano2 <- anosim(dune.dist, dune.env.original$Management) #compare groupings based on management
dune.ano2
plot(dune.ano2, sub = "Anosim, groups = management")
```

#### Question 28: SIMPER

After a significant ANOSIM, you may want to know which species are primarily responsible for the observed difference between clusters. SIMPER (Similarity Percentage) will do this for you. The test does not come with significance testing. In the output table, taxa are sorted in descending order of contribution to group difference. The last columns show the mean abundance in the groups.
```{r}

sim <- simper(dune, dune.env.original$Management)
sim

```

